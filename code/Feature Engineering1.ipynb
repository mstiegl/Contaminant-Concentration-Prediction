{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "from numpy import concatenate\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from __future__ import division  \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\HKUST\\data mining and knowledge discovery\\Project\\work2\n"
     ]
    }
   ],
   "source": [
    "cd D:\\HKUST\\data mining and knowledge discovery\\Project\\work2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_station_position = pd.read_csv('air_station_position.csv')\n",
    "aq_index = list(air_station_position['stationId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dongsi_aq',\n",
       " 'tiantan_aq',\n",
       " 'guanyuan_aq',\n",
       " 'wanshouxigong_aq',\n",
       " 'aotizhongxin_aq',\n",
       " 'nongzhanguan_aq',\n",
       " 'wanliu_aq',\n",
       " 'beibuxinqu_aq',\n",
       " 'zhiwuyuan_aq',\n",
       " 'fengtaihuayuan_aq',\n",
       " 'yungang_aq',\n",
       " 'gucheng_aq',\n",
       " 'fangshan_aq',\n",
       " 'daxing_aq',\n",
       " 'yizhuang_aq',\n",
       " 'tongzhou_aq',\n",
       " 'shunyi_aq',\n",
       " 'pingchang_aq',\n",
       " 'mentougou_aq',\n",
       " 'pinggu_aq',\n",
       " 'huairou_aq',\n",
       " 'miyun_aq',\n",
       " 'yanqin_aq',\n",
       " 'dingling_aq',\n",
       " 'badaling_aq',\n",
       " 'miyunshuiku_aq',\n",
       " 'donggaocun_aq',\n",
       " 'yongledian_aq',\n",
       " 'yufa_aq',\n",
       " 'liulihe_aq',\n",
       " 'qianmen_aq',\n",
       " 'yongdingmennei_aq',\n",
       " 'xizhimenbei_aq',\n",
       " 'nansanhuan_aq',\n",
       " 'dongsihuan_aq']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(aq_index)):\n",
    "    aq_index[i] = aq_index[i].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(a,b):\n",
    "    return list(set(a).intersection(set(b)))  \n",
    "    \n",
    "def get_aq_feature(df,time_list):\n",
    "    aq_feature = [[],[],[],[],[],[]]\n",
    "    for each in df.iterrows():\n",
    "        if each[1]['utc_time'] in time_list:\n",
    "            aq_feature[0].append(each[1]['PM2.5'])\n",
    "            aq_feature[1].append(each[1]['PM10'])\n",
    "            aq_feature[2].append(each[1]['NO2'])\n",
    "            aq_feature[3].append(each[1]['CO'])\n",
    "            aq_feature[4].append(each[1]['O3'])\n",
    "            aq_feature[5].append(each[1]['SO2'])\n",
    "    return aq_feature\n",
    "\n",
    "def get_meo_feature(df,time_list):\n",
    "    aq_feature = [[],[],[],[],[]]\n",
    "    for each in df.iterrows():\n",
    "        if each[1]['utc_time'] in time_list:\n",
    "            aq_feature[0].append(each[1]['temperature'])\n",
    "            aq_feature[1].append(each[1]['pressure'])\n",
    "            aq_feature[2].append(each[1]['humidity'])\n",
    "            aq_feature[3].append(each[1]['wind_direction'])\n",
    "            aq_feature[4].append(each[1]['wind_speed/kph'])\n",
    "    return aq_feature\n",
    "\n",
    "def get_time_feature(df,time_list):\n",
    "    aq_feature = [[],[],[],[]]\n",
    "    for each in df.iterrows():\n",
    "        if each[1]['utc_time'] in time_list:\n",
    "            # is weekday?\n",
    "            aq_feature[0].append(datetime.strptime(each[1]['utc_time'][:10], '%Y-%m-%d').weekday())\n",
    "            # is rush hour?\n",
    "            if each[1]['utc_time'][11:13] in ['00','01','02','09','10','11','12']:\n",
    "                aq_feature[1].append(1)\n",
    "            else:\n",
    "                aq_feature[1].append(0)\n",
    "            # is midnight?\n",
    "            if each[1]['utc_time'][11:13] in ['15','16','17','18','19','20','21','22']:\n",
    "                aq_feature[2].append(1)\n",
    "            else:\n",
    "                aq_feature[2].append(0)\n",
    "            # get month feature\n",
    "            aq_feature[3].append(each[1]['utc_time'][5:7])\n",
    "    return aq_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\HKUST\\data mining and knowledge discovery\\Project\\work2\\air condition data\n"
     ]
    }
   ],
   "source": [
    "cd D:\\HKUST\\data mining and knowledge discovery\\Project\\work2\\air condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:58<00:00,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for each in tqdm(aq_index):\n",
    "    aq_feature = []\n",
    "    # load file\n",
    "    df_aq = pd.read_csv('aq_17_18_split_'+ each + '.csv')\n",
    "    del df_aq['Unnamed: 0']\n",
    "    df_aq = df_aq.drop_duplicates(['utc_time'])\n",
    "    df_meo = pd.read_csv('D:/HKUST/data mining and knowledge discovery/Project/work2/air condition weather data/'+ each + '.csv')\n",
    "    del df_meo['Unnamed: 0']\n",
    "    df_meo = df_meo.drop_duplicates(['utc_time'])\n",
    "    # get time intersection index\n",
    "    aq_time_index = get_intersection(list(df_aq['utc_time']),list(df_meo['utc_time']))\n",
    "    # get value and feature\n",
    "    feature_aq = get_aq_feature(df_aq,aq_time_index)\n",
    "    feature_meo = get_meo_feature(df_meo,aq_time_index)\n",
    "    feature_time = get_time_feature(df_meo,aq_time_index)\n",
    "    aq_feature = feature_aq\n",
    "    aq_feature.extend(feature_meo)\n",
    "    aq_feature.extend(feature_time)\n",
    "    # feature to csv\n",
    "    aq_col_index = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2','temperature', 'pressure', 'humidity','wind_direction', 'wind_speed/kph','weekday','rush_time','mid_night','month']\n",
    "    aq_gen_df = DataFrame(np.transpose(aq_feature) ,index = None, columns = aq_col_index)\n",
    "    aq_gen_df.to_csv('D:/HKUST/data mining and knowledge discovery/Project/work2/feature data/' + 'feature_'+ each +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical characteristics of air quality in historical Windows were extracted\n",
    "def get_bin_feature(agg,city,n_bin,n_in):\n",
    "    if city == 0:\n",
    "        n_aq = 3\n",
    "    else:\n",
    "        n_aq = 6\n",
    "\n",
    "    stats_feature = []\n",
    "    for i in range(n_aq * 7):\n",
    "        stats_feature.append([])\n",
    "    # aq in df to list\n",
    "    df_aq = []\n",
    "    for i in range(n_aq):\n",
    "        for j in range(n_in-n_bin,n_in):\n",
    "            df_aq.append(list(agg['var'+str(i + 1)+'(t-'+str(j + 1)+')']))\n",
    "    # get statistics feature for each aq in historcal windows\n",
    "    aq = []\n",
    "    for i in range(n_aq * 7):\n",
    "        aq.append([])\n",
    "        # sample dimention\n",
    "    for i in tqdm(range(agg.shape[0])):\n",
    "        aq = []\n",
    "            # aq type numbers\n",
    "        for j in range(n_aq):\n",
    "            aq.append([])\n",
    "            for k in range(j * n_bin,(j + 1) * n_bin):\n",
    "                if np.isnan(df_aq[k][i]):\n",
    "                    aq[j].append(0)\n",
    "                else:\n",
    "                    aq[j].append(df_aq[k][i])\n",
    "            stats_feature[7 * j].append(statistics.mean(aq[j]))\n",
    "            stats_feature[7 * j + 1].append(statistics.median(aq[j]))\n",
    "            stats_feature[7 * j + 2].append(statistics.variance(aq[j]))\n",
    "            stats_feature[7 * j + 3].append(statistics.stdev(aq[j]))\n",
    "            stats_feature[7 * j + 4].append(max(aq[j]))\n",
    "            stats_feature[7 * j + 5].append(min(aq[j]))\n",
    "            stats_feature[7 * j + 6].append(max(aq[j]) - min(aq[j]))\n",
    "\n",
    "    insert_index = 0\n",
    "    for i in range(len(stats_feature)):\n",
    "        agg.insert(insert_index + i,'bin'+str(n_bin)+'-'+ str(i),stats_feature[i])\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "    \n",
    "# Turn sequences into supervised learning problems\n",
    "def series_to_supervised(data, meo, n_in = 1, n_out = 1, dropnan = True, city = 1):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # imput sequences(t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # prediction sequences (t, t+1, ... t+n)\n",
    "    for i in range(n_out - 1, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t + %d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # concat input sequences and prediction sequences\n",
    "    agg = concat(cols, axis = 1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # Clear the fields in the value window except for the target variable\n",
    "    drop_index = []\n",
    "    if city == 1:\n",
    "        index = [3,4,6,12,13]\n",
    "        for each in index:\n",
    "            drop_index.append('var' + str(each) + '(t + '+ str(n_out - 1)+')')\n",
    "    else:\n",
    "        index = [3,9,10]\n",
    "        for each in index:\n",
    "            drop_index.append('var' + str(each) + '(t + '+ str(n_out - 1)+')')\n",
    "    agg.drop(drop_index, axis = 1, inplace = True)\n",
    "    \n",
    "    if city == 0:\n",
    "        for i in range(2,n_in + 1):\n",
    "            t1 = i\n",
    "            for j in range(4,8):\n",
    "                t2 = j\n",
    "                agg.drop('var'+str(t2)+'(t-'+str(t1)+')', axis = 1, inplace = True)\n",
    "    else:\n",
    "        for i in range(2,n_in + 1):\n",
    "            t1 = i\n",
    "            for j in range(7,11):\n",
    "                t2 = j\n",
    "                agg.drop('var'+str(t2)+'(t-'+str(t1)+')', axis = 1, inplace = True)\n",
    "    \n",
    "    bin_index = [24,48]\n",
    "    for each in bin_index:\n",
    "        agg = get_bin_feature(agg,city,each,n_in)\n",
    "        \n",
    "    test_df = agg[-48:]\n",
    "    if city == 1:\n",
    "        test_df.drop('var1' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var2' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var5' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var7' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var8' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var9' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var10' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var11' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "    else:\n",
    "        test_df.drop('var1' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var2' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var4' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var5' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var6' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var7' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "        test_df.drop('var8' + '(t + '+ str(n_out - 1)+')',axis = 1, inplace = True)\n",
    "    \n",
    "    if city == 1:\n",
    "        meo.columns = ['var7(t + 71)','var8(t + 71)','var9(t + 71)','var10(t + 71)','var11(t + 71)']\n",
    "    else:\n",
    "        meo.columns = ['var4(t + 71)','var5(t + 71)','var6(t + 71)','var7(t + 71)','var8(t + 71)']\n",
    "    test_df = DataFrame(np.concatenate((test_df.values, meo.values), axis = 1))\n",
    "    \n",
    "    if dropnan:\n",
    "        agg.dropna(inplace = True)\n",
    "    \n",
    "    if city == 1:\n",
    "        bj_var1 = agg['var5(t + 71)']\n",
    "        agg.drop(labels=['var5(t + 71)'], axis=1,inplace = True)\n",
    "        agg.insert(0, 'var5(t + 71)', bj_var1)\n",
    "        bj_var2 = agg['var2(t + 71)']\n",
    "        agg.drop(labels=['var2(t + 71)'], axis=1,inplace = True)\n",
    "        agg.insert(0, 'var2(t + 71)', bj_var2)\n",
    "        bj_var5 = agg['var1(t + 71)']\n",
    "        agg.drop(labels=['var1(t + 71)'], axis=1,inplace = True)\n",
    "        agg.insert(0, 'var1(t + 71)', bj_var5)\n",
    "    else:\n",
    "        ld_var1 = agg['var2(t + 71)']\n",
    "        agg.drop(labels=['var2(t + 71)'], axis=1,inplace = True)\n",
    "        agg.insert(0, 'var2(t + 71)', ld_var1)\n",
    "        ld_var2 = agg['var1(t + 71)']\n",
    "        agg.drop(labels=['var1(t + 71)'], axis=1,inplace = True)\n",
    "        agg.insert(0, 'var1(t + 71)', ld_var2)\n",
    "    \n",
    "    if city == 1:\n",
    "        test_df.columns = list(agg.columns)[3:]\n",
    "    else:\n",
    "        test_df.columns = list(agg.columns)[2:]\n",
    "    res = [agg,test_df]\n",
    "    \n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
